{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI Engineering Bootcamp Cohort 4 Midterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install our key components for RAG etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain\n",
    "!pip install -q langchain-core==0.2.27 langchain-community==0.2.10\n",
    "!pip install -q langchain-experimental==0.0.64 langgraph-checkpoint==1.0.6 langgraph==0.2.16 langchain-qdrant==0.1.3\n",
    "!pip install -q langchain-openai==0.1.9\n",
    "!pip install -q ragas==0.1.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install our vector store - Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU qdrant-client==1.11.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install supporting utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU tiktoken==0.7.0 pymupdf==1.24.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment Variables\n",
    "\n",
    "- get OpenAI API Key - will use some of the OpenAI models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_api_key:\n",
    "    openai_api_key = getpass.getpass(\"OpenAI API Key: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up our starting inputs and state and read in the documents\n",
    "\n",
    "This allows to do do a lot of flexible testing to identify better decisions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.app_state import AppState\n",
    "from utilities.doc_utilities import get_documents\n",
    "document_urls = [\n",
    "    \"https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf\",\n",
    "     \"https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf\",\n",
    "]\n",
    "\n",
    "app_state = AppState()\n",
    "app_state.set_debug(False)\n",
    "\n",
    "app_state.set_document_urls(document_urls)\n",
    "\n",
    "get_documents(app_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up our first model run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created\n"
     ]
    }
   ],
   "source": [
    "from classes.model_run_state import ModelRunState\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from utilities.vector_utilities import create_vector_store\n",
    "\n",
    "model_1000_100_state = ModelRunState()\n",
    "model_1000_100_state.name = \"TE3/1000/100\"\n",
    "model_1000_100_state.chunk_size = 1000\n",
    "model_1000_100_state.chunk_overlap = 100\n",
    "\n",
    "model_1000_100_state.qa_model_name = \"gpt-4o-mini\"\n",
    "model_1000_100_state.qa_model = ChatOpenAI(model=model_1000_100_state.qa_model_name)\n",
    "\n",
    "# the openai embedding model\n",
    "model_1000_100_state.embedding_model_name = \"text-embedding-3-small\"\n",
    "model_1000_100_state.embedding_model = OpenAIEmbeddings(model=model_1000_100_state.embedding_model_name)\n",
    "\n",
    "create_vector_store(app_state, model_1000_100_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should be protected from abusive data practices via built-in \n",
      "protections and you should have agency over how data about \n",
      "you is used. You should be protected from violations of privacy through \n",
      "design choices that ensure such protections are included by default, including \n",
      "ensuring that data collection conforms to reasonable expectations and that \n",
      "only data strictly necessary for the specific context is collected. Designers, de­\n",
      "velopers, and deployers of automated systems should seek your permission \n",
      "and respect your decisions regarding collection, use, access, transfer, and de­\n",
      "letion of your data in appropriate ways and to the greatest extent possible; \n",
      "where not possible, alternative privacy by design safeguards should be used. \n",
      "Systems should not employ user experience and design decisions that obfus­\n",
      "cate user choice or burden users with defaults that are privacy invasive. Con­\n",
      "sent should only be used to justify collection of data in cases where it can be \n",
      "appropriately and meaningfully given. Any consent requests should be brief, \n",
      "be understandable in plain language, and give you agency over data collection \n",
      "and the specific context of use; current hard-to-understand no­\n",
      "tice-and-choice practices for broad uses of data should be changed. Enhanced \n",
      "protections and restrictions for data and inferences related to sensitive do­\n",
      "mains, including health, work, education, criminal justice, and finance, and \n",
      "for data pertaining to youth should put you first. In sensitive domains, your \n",
      "data and related inferences should only be used for necessary functions, and \n",
      "you should be protected by ethical review and use prohibitions. You and your \n",
      "communities should be free from unchecked surveillance; surveillance tech­\n",
      "nologies should be subject to heightened oversight that includes at least \n",
      "pre-deployment assessment of their potential harms and scope limits to pro­\n",
      "tect privacy and civil liberties. Continuous surveillance and monitoring \n",
      "should not be used in education, work, housing, or in other contexts where the \n",
      "use of such surveillance technologies is likely to limit rights, opportunities, or \n",
      "access. Whenever possible, you should have access to reporting that confirms \n",
      "your data decisions have been respected and provides an assessment of the \n",
      "potential impact of surveillance technologies on your rights, opportunities, or \n",
      "access. \n",
      "DATA PRIVACY\n",
      "30\n",
      "{'source': 'Blueprint for an AI Bill of Rights', 'document_id': '8fec76bd-d265-4782-8090-2bef9140fa2d', 'chunk_number': 25, '_id': 'db29a71d4e184278bce1a07e8271474f', '_collection_name': 'e0f280fce26d42cf9ee7472d430bccf9'}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rchrdgwr/anaconda3/envs/clean-llmops/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "query = \"How should you be protected from abusive data practices \"\n",
    "results = model_1000_100_state.retriever.get_relevant_documents(query)\n",
    "\n",
    "print(results[0].page_content)\n",
    "print(results[0].metadata)\n",
    "print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLUEPRINT FOR AN \n",
      "AI BILL OF \n",
      "RIGHTS \n",
      "MAKING AUTOMATED \n",
      "SYSTEMS WORK FOR \n",
      "THE AMERICAN PEOPLE \n",
      "OCTOBER 2022\n",
      "{'source': 'Blueprint for an AI Bill of Rights', 'document_id': '0c225ced-207c-4a0a-9925-28a6ad81a2ac', 'chunk_number': 1, '_id': '6913fb47c5384456bc64cc97986fc37b', '_collection_name': 'e1243742212d4c6eb16a99b4e28e318a'}\n",
      "---\n",
      "Table of Contents \n",
      "1. \n",
      "Introduction ..............................................................................................................................................1 \n",
      "2. \n",
      "Overview of Risks Unique to or Exacerbated by GAI .....................................................................2 \n",
      "3. \n",
      "Suggested Actions to Manage GAI Risks ......................................................................................... 12 \n",
      "Appendix A. Primary GAI Considerations ............................................................................................... 47 \n",
      "Appendix B. References ................................................................................................................................ 54 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\n",
      " \n",
      "1 \n",
      "1. \n",
      "Introduction \n",
      "This document is a cross-sectoral proﬁle of and companion resource for the AI Risk Management \n",
      "Framework (AI RMF 1.0) for Generative AI,1 pursuant to President Biden’s Executive Order (EO) 14110 on \n",
      "Safe, Secure, and Trustworthy Artiﬁcial Intelligence.2 The AI RMF was released in January 2023, and is \n",
      "intended for voluntary use and to improve the ability of organizations to incorporate trustworthiness \n",
      "considerations into the design, development, use, and evaluation of AI products, services, and systems.  \n",
      "A proﬁle is an implementation of the AI RMF functions, categories, and subcategories for a speciﬁc \n",
      "setting, application, or technology – in this case, Generative AI (GAI) – based on the requirements, risk \n",
      "tolerance, and resources of the Framework user. AI RMF proﬁles assist organizations in deciding how to \n",
      "best manage AI risks in a manner that is well-aligned with their goals, considers legal/regulatory \n",
      "requirements and best practices, and reﬂects risk management priorities. Consistent with other AI RMF \n",
      "proﬁles, this proﬁle oﬀers insights into how risk can be managed across various stages of the AI lifecycle \n",
      "and for GAI as a technology.  \n",
      "As GAI covers risks of models or applications that can be used across use cases or sectors, this document \n",
      "is an AI RMF cross-sectoral proﬁle. Cross-sectoral proﬁles can be used to govern, map, measure, and \n",
      "manage risks associated with activities or business processes common across sectors, such as the use of \n",
      "large language models (LLMs), cloud-based services, or acquisition. \n",
      "This document deﬁnes risks that are novel to or exacerbated by the use of GAI. After introducing and \n",
      "describing these risks, the document provides a set of suggested actions to help organizations govern, \n",
      "map, measure, and manage these risks. \n",
      " \n",
      " \n",
      "1 EO 14110 deﬁnes Generative AI as “the class of AI models that emulate the structure and characteristics of input \n",
      "data in order to generate derived synthetic content. This can include images, videos, audio, text, and other digital \n",
      "content.” While not all GAI is derived from foundation models, for purposes of this document, GAI generally refers \n",
      "to generative foundation models. The foundation model subcategory of “dual-use foundation models” is deﬁned by \n",
      "EO 14110 as “an AI model that is trained on broad data; generally uses self-supervision; contains at least tens of \n",
      "billions of parameters; is applicable across a wide range of contexts.”  \n",
      "2 This proﬁle was developed per Section 4.1(a)(i)(A) of EO 14110, which directs the Secretary of Commerce, acting \n",
      "through the Director of the National Institute of Standards and Technology (NIST), to develop a companion \n",
      "resource to the AI RMF, NIST AI 100–1, for generative AI.\n",
      "{'source': 'Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile', 'document_id': '052cfd45-f83a-4166-8e59-1b96e9e3fdd7', 'chunk_number': 2, '_id': 'e20fde6e92c940c4b412b3b37f678644', '_collection_name': 'e1243742212d4c6eb16a99b4e28e318a'}\n",
      "---\n",
      "54 \n",
      "Appendix B. References \n",
      "Acemoglu, D. (2024) The Simple Macroeconomics of AI https://www.nber.org/papers/w32487 \n",
      "AI Incident Database. https://incidentdatabase.ai/ \n",
      "Atherton, D. (2024) Deepfakes and Child Safety: A Survey and Analysis of 2023 Incidents and Responses. \n",
      "AI Incident Database. https://incidentdatabase.ai/blog/deepfakes-and-child-safety/ \n",
      "Badyal, N. et al. (2023) Intentional Biases in LLM Responses. arXiv. https://arxiv.org/pdf/2311.07611 \n",
      "Bing Chat: Data Exﬁltration Exploit Explained. Embrace The Red. \n",
      "https://embracethered.com/blog/posts/2023/bing-chat-data-exﬁltration-poc-and-ﬁx/ \n",
      "Bommasani, R. et al. (2022) Picking on the Same Person: Does Algorithmic Monoculture lead to Outcome \n",
      "Homogenization? arXiv. https://arxiv.org/pdf/2211.13972 \n",
      "Boyarskaya, M. et al. (2020) Overcoming Failures of Imagination in AI Infused System Development and \n",
      "Deployment. arXiv. https://arxiv.org/pdf/2011.13416 \n",
      "Browne, D. et al. (2023) Securing the AI Pipeline. Mandiant. \n",
      "https://www.mandiant.com/resources/blog/securing-ai-pipeline \n",
      "Burgess, M. (2024) Generative AI’s Biggest Security Flaw Is Not Easy to Fix. WIRED. \n",
      "https://www.wired.com/story/generative-ai-prompt-injection-hacking/ \n",
      "Burtell, M. et al. (2024) The Surprising Power of Next Word Prediction: Large Language Models \n",
      "Explained, Part 1. Georgetown Center for Security and Emerging Technology. \n",
      "https://cset.georgetown.edu/article/the-surprising-power-of-next-word-prediction-large-language-\n",
      "models-explained-part-1/ \n",
      "Canadian Centre for Cyber Security (2023) Generative artiﬁcial intelligence (AI) - ITSAP.00.041. \n",
      "https://www.cyber.gc.ca/en/guidance/generative-artiﬁcial-intelligence-ai-itsap00041 \n",
      "Carlini, N., et al. (2021) Extracting Training Data from Large Language Models. Usenix. \n",
      "https://www.usenix.org/conference/usenixsecurity21/presentation/carlini-extracting \n",
      "Carlini, N. et al. (2023) Quantifying Memorization Across Neural Language Models. ICLR 2023. \n",
      "https://arxiv.org/pdf/2202.07646 \n",
      "Carlini, N. et al. (2024) Stealing Part of a Production Language Model. arXiv. \n",
      "https://arxiv.org/abs/2403.06634 \n",
      "Chandra, B. et al. (2023) Dismantling the Disinformation Business of Chinese Inﬂuence Operations. \n",
      "RAND. https://www.rand.org/pubs/commentary/2023/10/dismantling-the-disinformation-business-of-\n",
      "chinese.html \n",
      "Ciriello, R. et al. (2024) Ethical Tensions in Human-AI Companionship: A Dialectical Inquiry into Replika. \n",
      "ResearchGate. https://www.researchgate.net/publication/374505266_Ethical_Tensions_in_Human-\n",
      "AI_Companionship_A_Dialectical_Inquiry_into_Replika \n",
      "Dahl, M. et al. (2024) Large Legal Fictions: Proﬁling Legal Hallucinations in Large Language Models. arXiv. \n",
      "https://arxiv.org/abs/2401.01301\n",
      "{'source': 'Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile', 'document_id': '052cfd45-f83a-4166-8e59-1b96e9e3fdd7', 'chunk_number': 47, '_id': 'aca655485039475b837751ab9c792a06', '_collection_name': 'e1243742212d4c6eb16a99b4e28e318a'}\n",
      "---\n",
      "58 \n",
      "Satariano, A. et al. (2023) The People Onscreen Are Fake. The Disinformation Is Real. New York Times. \n",
      "https://www.nytimes.com/2023/02/07/technology/artiﬁcial-intelligence-training-deepfake.html \n",
      "Schaul, K. et al. (2024) Inside the secret list of websites that make AI like ChatGPT sound smart. \n",
      "Washington Post. https://www.washingtonpost.com/technology/interactive/2023/ai-chatbot-learning/ \n",
      "Scheurer, J. et al. (2023) Technical report: Large language models can strategically deceive their users \n",
      "when put under pressure. arXiv. https://arxiv.org/abs/2311.07590 \n",
      "Shelby, R. et al. (2023) Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm \n",
      "Reduction. arXiv. https://arxiv.org/pdf/2210.05791 \n",
      "Shevlane, T. et al. (2023) Model evaluation for extreme risks. arXiv. https://arxiv.org/pdf/2305.15324 \n",
      "Shumailov, I. et al. (2023) The curse of recursion: training on generated data makes models forget. arXiv. \n",
      "https://arxiv.org/pdf/2305.17493v2 \n",
      "Smith, A. et al. (2023) Hallucination or Confabulation? Neuroanatomy as metaphor in Large Language \n",
      "Models. PLOS Digital Health. \n",
      "https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000388 \n",
      "Soice, E. et al. (2023) Can large language models democratize access to dual-use biotechnology? arXiv. \n",
      "https://arxiv.org/abs/2306.03809 \n",
      "Solaiman, I. et al. (2023) The Gradient of Generative AI Release: Methods and Considerations. arXiv. \n",
      "https://arxiv.org/abs/2302.04844 \n",
      "Staab, R. et al. (2023) Beyond Memorization: Violating Privacy via Inference With Large Language \n",
      "Models. arXiv. https://arxiv.org/pdf/2310.07298 \n",
      "Stanford, S. et al. (2023) Whose Opinions Do Language Models Reﬂect? arXiv. \n",
      "https://arxiv.org/pdf/2303.17548 \n",
      "Strubell, E. et al. (2019) Energy and Policy Considerations for Deep Learning in NLP. arXiv. \n",
      "https://arxiv.org/pdf/1906.02243 \n",
      "The White House (2016) Circular No. A-130, Managing Information as a Strategic Resource. \n",
      "https://www.whitehouse.gov/wp-\n",
      "content/uploads/legacy_drupal_ﬁles/omb/circulars/A130/a130revised.pdf \n",
      "The White House (2023) Executive Order on the Safe, Secure, and Trustworthy Development and Use of \n",
      "Artiﬁcial Intelligence. https://www.whitehouse.gov/brieﬁng-room/presidential-\n",
      "actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-\n",
      "artiﬁcial-intelligence/ \n",
      "The White House (2022) Roadmap for Researchers on Priorities Related to Information Integrity \n",
      "Research and Development. https://www.whitehouse.gov/wp-content/uploads/2022/12/Roadmap-\n",
      "Information-Integrity-RD-2022.pdf? \n",
      "Thiel, D. (2023) Investigation Finds AI Image Generation Models Trained on Child Abuse. Stanford Cyber \n",
      "Policy Center. https://cyber.fsi.stanford.edu/news/investigation-ﬁnds-ai-image-generation-models-\n",
      "trained-child-abuse\n",
      "{'source': 'Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile', 'document_id': '052cfd45-f83a-4166-8e59-1b96e9e3fdd7', 'chunk_number': 51, '_id': '69bc2d9bab704d6496e19737a94c048b', '_collection_name': 'e1243742212d4c6eb16a99b4e28e318a'}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "query = \"tell me about Karen Hao\"\n",
    "results = model_1000_100_state.retriever.get_relevant_documents(query)\n",
    "\n",
    "for result in results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.templates import get_qa_prompt\n",
    "from langchain_openai import ChatOpenAI\n",
    "from operator import itemgetter\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from utilities.debugger import dprint\n",
    "\n",
    "def create_rag_chain(app_state, model_run_state):\n",
    "\n",
    "    chat_prompt = get_qa_prompt()\n",
    "\n",
    "    simple_chain = chat_prompt | model_run_state.qa_model\n",
    "    dprint(app_state, simple_chain.invoke({\"question\": \"Can you give me a summary of the 2 documents\", \"context\":\"\"}))\n",
    "\n",
    "    rag_qa_chain = (\n",
    "        {\"context\": itemgetter(\"question\") | model_run_state.retriever, \"question\": itemgetter(\"question\")}\n",
    "        | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "\n",
    "\n",
    "        | {\"response\": chat_prompt | model_run_state.qa_model, \"context\": itemgetter(\"context\")}\n",
    "    )\n",
    "    response = rag_qa_chain.invoke({\"question\" : \"What is the AI Bill of Rights \"})\n",
    "    dprint(app_state, response)\n",
    "    dprint(app_state, response[\"response\"].content)\n",
    "    dprint(app_state, f\"Number of found context: {len(response['context'])}\")\n",
    "    model_run_state.rag_qa_chain = rag_qa_chain\n",
    "    print(\"RAG Chain Created\")\n",
    "\n",
    "create_rag_chain(app_state, model_1000_100_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get the SDG done for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num chumks: 439\n",
      "Num chumks: 322\n",
      "Total chunks: 761\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.                     \n",
      "Generating: 100%|██████████| 3/3 [00:12<00:00,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragas questions created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from classes.ragas_state import RagasState\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# create document chunks\n",
    "def Create_chunks_for_ragas(app_state, ragas_state):\n",
    "    # we have 2 documents so want representative across both\n",
    "    text_splitter_eval = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = ragas_state.chunk_size,\n",
    "        chunk_overlap = ragas_state.chunk_overlap,\n",
    "        length_function = len\n",
    "    )\n",
    "    combined_chunks_document = []\n",
    "    for document in app_state.documents:\n",
    "        eval_document = document[\"loaded_document\"]\n",
    "        document_chunks = text_splitter_eval.split_documents(eval_document)\n",
    "        print(f\"Num chumks: {len(document_chunks)}\")\n",
    "        combined_chunks_document = combined_chunks_document + document_chunks\n",
    "\n",
    "    print(f\"Total chunks: {len(combined_chunks_document)}\")\n",
    "    ragas_state.chunks = combined_chunks_document\n",
    "    print()\n",
    "\n",
    "# create the questions\n",
    "def create_questions_for_ragas(app_state, ragas_state):\n",
    "    generator_llm = ChatOpenAI(model=ragas_state.generator_llm)\n",
    "    critic_llm = ChatOpenAI(model=ragas_state.critic_llm)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    generator = TestsetGenerator.from_langchain(\n",
    "        generator_llm,\n",
    "        critic_llm,\n",
    "        embeddings\n",
    "    )\n",
    "\n",
    "    testset = generator.generate_with_langchain_docs(\n",
    "        ragas_state.chunks,\n",
    "        ragas_state.num_questions, \n",
    "        ragas_state.distributions)\n",
    "    # state.set_ragas_testset(testset)\n",
    "    testset.to_pandas()\n",
    "    testset.test_data[0]\n",
    "    testset_df = testset.to_pandas()\n",
    "    ragas_state.testset_df = testset_df\n",
    "    print(\"Ragas questions created\")\n",
    "    testset_df\n",
    "\n",
    "ragas_state = RagasState()\n",
    "Create_chunks_for_ragas(app_state, ragas_state)\n",
    "create_questions_for_ragas(app_state, ragas_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate answers based on the pipeline we have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers created - ready for Ragas evaluation\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "def create_answers(app_state, model_run_state, ragas_state):\n",
    "  answers = []\n",
    "  contexts = []\n",
    "\n",
    "  test_questions = ragas_state.testset_df[\"question\"].values.tolist()\n",
    "  test_groundtruths = ragas_state.testset_df[\"ground_truth\"].values.tolist()\n",
    "\n",
    "  for question in test_questions:\n",
    "    response = model_run_state.rag_qa_chain.invoke({\"question\" : question})\n",
    "    answers.append(response[\"response\"].content)\n",
    "    contexts.append([context.page_content for context in response[\"context\"]])\n",
    "\n",
    "  # Wrap it in a huggingface dataset\n",
    "  model_run_state.response_dataset = Dataset.from_dict({\n",
    "      \"question\" : test_questions,\n",
    "      \"answer\" : answers,\n",
    "      \"contexts\" : contexts,\n",
    "      \"ground_truth\" : test_groundtruths\n",
    "  })\n",
    "  model_run_state.response_dataset[0]\n",
    "  print(\"Answers created - ready for Ragas evaluation\")\n",
    "\n",
    "create_answers(app_state, model_1000_100_state, ragas_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 15/15 [00:13<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragas evaluation complete\n"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "def run_ragas_evaluation(app_state, model_run_state):\n",
    "    metrics = [\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_precision,\n",
    "        answer_correctness,\n",
    "    ]\n",
    "    model_run_state.ragas_results = evaluate(model_run_state.response_dataset, metrics)\n",
    "    print(\"Ragas evaluation complete\")\n",
    "run_ragas_evaluation(app_state, model_1000_100_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model: gpt-4o-mini\n",
      "Embedding model: Snowflake/snowflake-arctic-embed-m\n",
      "Chink size: 1000\n",
      "Chink overlap: 100\n",
      "{'faithfulness': 0.6359, 'answer_relevancy': 0.9478, 'context_recall': 0.8333, 'context_precision': 1.0000, 'answer_correctness': 0.6633}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>answer_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can new GAI policies, procedures, and proc...</td>\n",
       "      <td>The new policies, procedures, and processes fo...</td>\n",
       "      <td>[19 \\nGV-4.1-003 \\nEstablish policies, procedu...</td>\n",
       "      <td>New GAI policies, procedures, and processes ca...</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.940980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.549834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does confirmation bias contribute to poten...</td>\n",
       "      <td>Confirmation bias can significantly contribute...</td>\n",
       "      <td>[Algorithmic \\nDiscrimination \\nProtections \\n...</td>\n",
       "      <td>Confirmation bias contributes to potentially i...</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.966214</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What resources on AI risk management are avail...</td>\n",
       "      <td>The National Institute of Standards and Techno...</td>\n",
       "      <td>[NIST Trustworthy and Responsible AI  \\nNIST A...</td>\n",
       "      <td>The National Institute of Standards and Techno...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.936206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.595151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How can new GAI policies, procedures, and proc...   \n",
       "1  How does confirmation bias contribute to poten...   \n",
       "2  What resources on AI risk management are avail...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The new policies, procedures, and processes fo...   \n",
       "1  Confirmation bias can significantly contribute...   \n",
       "2  The National Institute of Standards and Techno...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [19 \\nGV-4.1-003 \\nEstablish policies, procedu...   \n",
       "1  [Algorithmic \\nDiscrimination \\nProtections \\n...   \n",
       "2  [NIST Trustworthy and Responsible AI  \\nNIST A...   \n",
       "\n",
       "                                        ground_truth  faithfulness  \\\n",
       "0  New GAI policies, procedures, and processes ca...      0.416667   \n",
       "1  Confirmation bias contributes to potentially i...      0.562500   \n",
       "2  The National Institute of Standards and Techno...      0.928571   \n",
       "\n",
       "   answer_relevancy  context_recall  context_precision  answer_correctness  \n",
       "0          0.940980             1.0                1.0            0.549834  \n",
       "1          0.966214             0.5                1.0            0.844938  \n",
       "2          0.936206             1.0                1.0            0.595151  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1000_100_state.parameters()\n",
    "#model_1000_100_state.results_summary()\n",
    "model_1000_100_state.results()\n",
    "\n",
    "print(model_1000_100_state.ragas_results)\n",
    "results_df = model_1000_100_state.ragas_results.to_pandas()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created\n",
      "Answers created - ready for Ragas evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 15/15 [00:14<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragas evaluation complete\n"
     ]
    }
   ],
   "source": [
    "snowflake_base_state = ModelRunState()\n",
    "snowflake_base_state.name = \"Snowflake_Base/1000/100\"\n",
    "snowflake_base_state.qa_model_name = \"gpt-4o-mini\"\n",
    "snowflake_base_state.qa_model = ChatOpenAI(model=snowflake_base_state.qa_model_name)\n",
    "\n",
    "# snowflake embedding model\n",
    "snowflake_base_state.embedding_model_name = \"Snowflake/snowflake-arctic-embed-m\"\n",
    "snowflake_base_state.embedding_model = HuggingFaceEmbeddings(model_name=snowflake_base_state.embedding_model_name)\n",
    "\n",
    "# use same chunk size as before\n",
    "snowflake_base_state.chunk_size = 1000\n",
    "snowflake_base_state.chunk_overlap = 100\n",
    "create_vector_store(app_state, snowflake_base_state)\n",
    "\n",
    "create_rag_chain(app_state, snowflake_base_state)\n",
    "create_answers(app_state, snowflake_base_state, ragas_state)\n",
    "run_ragas_evaluation(app_state, snowflake_base_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model: gpt-4o-mini\n",
      "Embedding model: Snowflake/snowflake-arctic-embed-m\n",
      "Chink size: 1000\n",
      "Chink overlap: 100\n",
      "{'faithfulness': 0.4478, 'answer_relevancy': 0.6039, 'context_recall': 0.3333, 'context_precision': 0.5833, 'answer_correctness': 0.3635}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>answer_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can new GAI policies, procedures, and proc...</td>\n",
       "      <td>The connection between new Generative AI (GAI)...</td>\n",
       "      <td>[Table of Contents \\n1. \\nIntroduction ..........</td>\n",
       "      <td>New GAI policies, procedures, and processes ca...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.892835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.506942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does confirmation bias contribute to poten...</td>\n",
       "      <td>I don't have enough information, sorry. Howeve...</td>\n",
       "      <td>[BLUEPRINT FOR AN \\nAI BILL OF \\nRIGHTS \\nMAKI...</td>\n",
       "      <td>Confirmation bias contributes to potentially i...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What resources on AI risk management are avail...</td>\n",
       "      <td>The National Institute of Standards and Techno...</td>\n",
       "      <td>[57 \\nNational Institute of Standards and Tech...</td>\n",
       "      <td>The National Institute of Standards and Techno...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.918800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.404474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How can new GAI policies, procedures, and proc...   \n",
       "1  How does confirmation bias contribute to poten...   \n",
       "2  What resources on AI risk management are avail...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The connection between new Generative AI (GAI)...   \n",
       "1  I don't have enough information, sorry. Howeve...   \n",
       "2  The National Institute of Standards and Techno...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Table of Contents \\n1. \\nIntroduction ..........   \n",
       "1  [BLUEPRINT FOR AN \\nAI BILL OF \\nRIGHTS \\nMAKI...   \n",
       "2  [57 \\nNational Institute of Standards and Tech...   \n",
       "\n",
       "                                        ground_truth  faithfulness  \\\n",
       "0  New GAI policies, procedures, and processes ca...      0.454545   \n",
       "1  Confirmation bias contributes to potentially i...      0.000000   \n",
       "2  The National Institute of Standards and Techno...      0.888889   \n",
       "\n",
       "   answer_relevancy  context_recall  context_precision  answer_correctness  \n",
       "0          0.892835             0.0           0.833333            0.506942  \n",
       "1          0.000000             0.0           0.000000            0.179080  \n",
       "2          0.918800             1.0           0.916667            0.404474  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "snowflake_base_state.parameters()\n",
    "print(snowflake_base_state.ragas_results)\n",
    "results_df = snowflake_base_state.ragas_results.to_pandas()\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare Snowflake base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Snowflake_Base/1000/100</th>\n",
       "      <th>TE3/1000/100</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.447811</td>\n",
       "      <td>0.635913</td>\n",
       "      <td>0.188101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.603878</td>\n",
       "      <td>0.947800</td>\n",
       "      <td>0.343922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context_recall</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context_precision</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer_correctness</td>\n",
       "      <td>0.363499</td>\n",
       "      <td>0.663308</td>\n",
       "      <td>0.299809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric  Snowflake_Base/1000/100  TE3/1000/100  Difference\n",
       "0        faithfulness                 0.447811      0.635913    0.188101\n",
       "1    answer_relevancy                 0.603878      0.947800    0.343922\n",
       "2      context_recall                 0.333333      0.833333    0.500000\n",
       "3   context_precision                 0.583333      1.000000    0.416667\n",
       "4  answer_correctness                 0.363499      0.663308    0.299809"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def compare_results(run_model_1, run_model_2):\n",
    "    results_1 = run_model_1.ragas_results\n",
    "    results_2 = run_model_2.ragas_results\n",
    "    comparison_data = {\n",
    "        'Metric': list(results_1.keys()),\n",
    "        run_model_1.name: [results_1[key] for key in results_1.keys()],\n",
    "        run_model_2.name: [results_2[key] for key in results_2.keys()],\n",
    "        'Difference': [results_2[key] - results_1[key] for key in results_1.keys()]\n",
    "    }\n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "snowflake_base_state.name = \"Snowflake_Base/1000/100\"\n",
    "model_1000_100_state.name = \"TE3/1000/100\"\n",
    "df = compare_results(snowflake_base_state, model_1000_100_state )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take the fine tuned model for a run and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.app_state import AppState\n",
    "from classes.model_run_state import ModelRunState\n",
    "from classes.ragas_state import RagasState\n",
    "from utilities.doc_utilities import get_documents\n",
    "from utilities.vector_utilities import create_vector_store\n",
    "\n",
    "# document_urls = [\n",
    "#     \"https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf\",\n",
    "#      \"https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf\",\n",
    "# ]\n",
    "\n",
    "# app_state_2 = AppState()\n",
    "# app_state_2.set_debug(False)\n",
    "# app_state_2.set_document_urls(document_urls)\n",
    "\n",
    "# get_documents(app_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at rchrdgwr/finetuned-arctic-model and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created\n",
      "Answers created - ready for Ragas evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 15/15 [00:19<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragas evaluation complete\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "snowflake_finetune_state = ModelRunState()\n",
    "snowflake_finetune_state.name = \"Snowflake_Fine/1000/100\"\n",
    "snowflake_finetune_state.qa_model_name = \"gpt-4o-mini\"\n",
    "snowflake_finetune_state.qa_model = ChatOpenAI(model=snowflake_finetune_state.qa_model_name)\n",
    "\n",
    "# finetune snowflake embedding model\n",
    "\n",
    "hf_username = \"rchrdgwr\"\n",
    "hf_repo_name = \"finetuned-arctic-model\"\n",
    "\n",
    "# Load the fine-tuned model from Hugging Face\n",
    "snowflake_finetune_state.embedding_model_name = f\"{hf_username}/{hf_repo_name}\"\n",
    "snowflake_finetune_state.embedding_model = HuggingFaceEmbeddings(model_name=snowflake_finetune_state.embedding_model_name)\n",
    "\n",
    "# use same chunk size as before\n",
    "snowflake_finetune_state.chunk_size = 1000\n",
    "snowflake_finetune_state.chunk_overlap = 100\n",
    "create_vector_store(app_state, snowflake_finetune_state)\n",
    "\n",
    "create_rag_chain(app_state, snowflake_finetune_state)\n",
    "create_answers(app_state, snowflake_finetune_state, ragas_state)\n",
    "run_ragas_evaluation(app_state, snowflake_finetune_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model: gpt-4o-mini\n",
      "Embedding model: rchrdgwr/finetuned-arctic-model\n",
      "Chink size: 1000\n",
      "Chink overlap: 100\n",
      "{'faithfulness': 0.9103, 'answer_relevancy': 0.9455, 'context_recall': 0.8889, 'context_precision': 1.0000, 'answer_correctness': 0.4178}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>answer_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can new GAI policies, procedures, and proc...</td>\n",
       "      <td>New GAI (Generative Artificial Intelligence) p...</td>\n",
       "      <td>[19 \\nGV-4.1-003 \\nEstablish policies, procedu...</td>\n",
       "      <td>New GAI policies, procedures, and processes ca...</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.934013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.527957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does confirmation bias contribute to poten...</td>\n",
       "      <td>Confirmation bias can contribute to potentiall...</td>\n",
       "      <td>[Algorithmic \\nDiscrimination \\nProtections \\n...</td>\n",
       "      <td>Confirmation bias contributes to potentially i...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966214</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.336860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What resources on AI risk management are avail...</td>\n",
       "      <td>The National Institute of Standards and Techno...</td>\n",
       "      <td>[NIST Trustworthy and Responsible AI  \\nNIST A...</td>\n",
       "      <td>The National Institute of Standards and Techno...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.936206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.388704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How can new GAI policies, procedures, and proc...   \n",
       "1  How does confirmation bias contribute to poten...   \n",
       "2  What resources on AI risk management are avail...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  New GAI (Generative Artificial Intelligence) p...   \n",
       "1  Confirmation bias can contribute to potentiall...   \n",
       "2  The National Institute of Standards and Techno...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [19 \\nGV-4.1-003 \\nEstablish policies, procedu...   \n",
       "1  [Algorithmic \\nDiscrimination \\nProtections \\n...   \n",
       "2  [NIST Trustworthy and Responsible AI  \\nNIST A...   \n",
       "\n",
       "                                        ground_truth  faithfulness  \\\n",
       "0  New GAI policies, procedures, and processes ca...      0.730769   \n",
       "1  Confirmation bias contributes to potentially i...      1.000000   \n",
       "2  The National Institute of Standards and Techno...      1.000000   \n",
       "\n",
       "   answer_relevancy  context_recall  context_precision  answer_correctness  \n",
       "0          0.934013        1.000000                1.0            0.527957  \n",
       "1          0.966214        0.666667                1.0            0.336860  \n",
       "2          0.936206        1.000000                1.0            0.388704  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowflake_finetune_state.parameters()\n",
    "print(snowflake_finetune_state.ragas_results)\n",
    "results_df = snowflake_finetune_state.ragas_results.to_pandas()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>TE3/1000/100</th>\n",
       "      <th>Snowflake_Base/1000/100</th>\n",
       "      <th>Snowflake_Fine/1000/100</th>\n",
       "      <th>1v2 Difference</th>\n",
       "      <th>1v3 Difference</th>\n",
       "      <th>2v3 Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.635913</td>\n",
       "      <td>0.447811</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>-0.188101</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>0.462445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.947800</td>\n",
       "      <td>0.603878</td>\n",
       "      <td>0.945477</td>\n",
       "      <td>-0.343922</td>\n",
       "      <td>-0.002323</td>\n",
       "      <td>0.341599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context_recall</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context_precision</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer_correctness</td>\n",
       "      <td>0.663308</td>\n",
       "      <td>0.363499</td>\n",
       "      <td>0.417840</td>\n",
       "      <td>-0.299809</td>\n",
       "      <td>-0.245467</td>\n",
       "      <td>0.054342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric  TE3/1000/100  Snowflake_Base/1000/100  \\\n",
       "0        faithfulness      0.635913                 0.447811   \n",
       "1    answer_relevancy      0.947800                 0.603878   \n",
       "2      context_recall      0.833333                 0.333333   \n",
       "3   context_precision      1.000000                 0.583333   \n",
       "4  answer_correctness      0.663308                 0.363499   \n",
       "\n",
       "   Snowflake_Fine/1000/100  1v2 Difference  1v3 Difference  2v3 Difference  \n",
       "0                 0.910256       -0.188101        0.274344        0.462445  \n",
       "1                 0.945477       -0.343922       -0.002323        0.341599  \n",
       "2                 0.888889       -0.500000        0.055556        0.555556  \n",
       "3                 1.000000       -0.416667        0.000000        0.416667  \n",
       "4                 0.417840       -0.299809       -0.245467        0.054342  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def compare_results_3(run_model_1, run_model_2, run_model_3):\n",
    "    # Extract results for each model\n",
    "    results_1 = run_model_1.ragas_results\n",
    "    results_2 = run_model_2.ragas_results\n",
    "    results_3 = run_model_3.ragas_results\n",
    "\n",
    "    # Create comparison data\n",
    "    comparison_data = {\n",
    "        'Metric': list(results_1.keys()),\n",
    "        run_model_1.name: [results_1[key] for key in results_1.keys()],\n",
    "        run_model_2.name: [results_2[key] for key in results_2.keys()],\n",
    "        run_model_3.name: [results_3[key] for key in results_3.keys()],\n",
    "        '1v2 Difference': [results_2[key] - results_1[key] for key in results_1.keys()],\n",
    "        '1v3 Difference': [results_3[key] - results_1[key] for key in results_1.keys()],\n",
    "        '2v3 Difference': [results_3[key] - results_2[key] for key in results_2.keys()]\n",
    "    }\n",
    "\n",
    "    # Return the dataframe\n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "snowflake_base_state.name = \"Snowflake_Base/1000/100\"\n",
    "model_1000_100_state.name = \"TE3/1000/100\"\n",
    "df = compare_results_3(model_1000_100_state , snowflake_base_state,  snowflake_finetune_state)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at rchrdgwr/finetuned-arctic-model and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "hf_username = \"rchrdgwr\"\n",
    "hf_repo_name = \"finetuned-arctic-model\"\n",
    "\n",
    "snowflake_finetune_model_name = f\"{hf_username}/{hf_repo_name}\"\n",
    "snowflake_finetune_model = HuggingFaceEmbeddings(model_name=snowflake_finetune_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at rchrdgwr/finetuned-arctic-model and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created\n",
      "Answers created - ready for Ragas evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragas evaluation complete\n",
      "{'faithfulness': 0.9010, 'answer_relevancy': 0.9697, 'context_recall': 0.8889, 'context_precision': 1.0000, 'answer_correctness': 0.3700}\n"
     ]
    }
   ],
   "source": [
    "from utilities.constants import (\n",
    "    CHUNKING_STRATEGY_TABLE_AWARE,\n",
    "    CHUNKING_STRATEGY_SECTION_BASED,\n",
    "    CHUNKING_STRATEGY_SEMANTIC\n",
    ")\n",
    "\n",
    "snowflake_finetune_section_state = ModelRunState()\n",
    "snowflake_finetune_section_state.name = \"Snowflake_FineSection/1000/100\"\n",
    "snowflake_finetune_section_state.qa_model_name = \"gpt-4o-mini\"\n",
    "snowflake_finetune_section_state.qa_model = ChatOpenAI(model=snowflake_finetune_section_state.qa_model_name)\n",
    "\n",
    "snowflake_finetune_section_state.embedding_model_name = snowflake_finetune_model_name\n",
    "snowflake_finetune_section_state.embedding_model = snowflake_finetune_model\n",
    "\n",
    "# use same chunk size as before\n",
    "snowflake_finetune_section_state.chunking_strategy = CHUNKING_STRATEGY_SECTION_BASED\n",
    "snowflake_finetune_section_state.chunk_size = 1000\n",
    "snowflake_finetune_section_state.chunk_overlap = 100\n",
    "create_vector_store(app_state, snowflake_finetune_section_state)\n",
    "\n",
    "create_rag_chain(app_state, snowflake_finetune_section_state)\n",
    "create_answers(app_state, snowflake_finetune_section_state, ragas_state)\n",
    "run_ragas_evaluation(app_state, snowflake_finetune_section_state)\n",
    "print(snowflake_finetune_section_state.ragas_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created\n",
      "Answers created - ready for Ragas evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 15/15 [00:17<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragas evaluation complete\n",
      "{'faithfulness': 0.6922, 'answer_relevancy': 0.9457, 'context_recall': 0.8889, 'context_precision': 1.0000, 'answer_correctness': 0.4848}\n"
     ]
    }
   ],
   "source": [
    "snowflake_finetune_table_state = ModelRunState()\n",
    "snowflake_finetune_table_state.name = \"Snowflake_FineTable/1000/100\"\n",
    "snowflake_finetune_table_state.qa_model_name = \"gpt-4o-mini\"\n",
    "snowflake_finetune_table_state.qa_model = ChatOpenAI(model=snowflake_finetune_table_state.qa_model_name)\n",
    "\n",
    "snowflake_finetune_table_state.embedding_model_name = snowflake_finetune_model_name\n",
    "snowflake_finetune_table_state.embedding_model = snowflake_finetune_model\n",
    "\n",
    "# use same chunk size as before\n",
    "snowflake_finetune_table_state.chunking_strategy = CHUNKING_STRATEGY_TABLE_AWARE\n",
    "snowflake_finetune_table_state.chunk_size = 1000\n",
    "snowflake_finetune_table_state.chunk_overlap = 100\n",
    "create_vector_store(app_state, snowflake_finetune_table_state)\n",
    "\n",
    "create_rag_chain(app_state, snowflake_finetune_table_state)\n",
    "create_answers(app_state, snowflake_finetune_table_state, ragas_state)\n",
    "run_ragas_evaluation(app_state, snowflake_finetune_table_state)\n",
    "print(snowflake_finetune_table_state.ragas_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created\n",
      "Answers created - ready for Ragas evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 15/15 [00:12<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragas evaluation complete\n",
      "{'faithfulness': 0.8889, 'answer_relevancy': 0.9592, 'context_recall': 0.8889, 'context_precision': 1.0000, 'answer_correctness': 0.6295}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "snowflake_finetune_semantic_state = ModelRunState()\n",
    "snowflake_finetune_semantic_state.name = \"Snowflake_FineSemantic/1000/100\"\n",
    "snowflake_finetune_semantic_state.qa_model_name = \"gpt-4o-mini\"\n",
    "snowflake_finetune_semantic_state.qa_model = ChatOpenAI(model=snowflake_finetune_semantic_state.qa_model_name)\n",
    "\n",
    "snowflake_finetune_semantic_state.embedding_model_name = snowflake_finetune_model_name\n",
    "snowflake_finetune_semantic_state.embedding_model = snowflake_finetune_model\n",
    "\n",
    "# use same chunk size as before\n",
    "snowflake_finetune_semantic_state.chunking_strategy = CHUNKING_STRATEGY_SEMANTIC\n",
    "snowflake_finetune_semantic_state.chunk_size = 1000\n",
    "snowflake_finetune_semantic_state.chunk_overlap = 100\n",
    "create_vector_store(app_state, snowflake_finetune_semantic_state)\n",
    "\n",
    "create_rag_chain(app_state, snowflake_finetune_semantic_state)\n",
    "create_answers(app_state, snowflake_finetune_semantic_state, ragas_state)\n",
    "run_ragas_evaluation(app_state, snowflake_finetune_semantic_state)\n",
    "print(snowflake_finetune_semantic_state.ragas_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Snowflake_Fine/1000/100</th>\n",
       "      <th>Snowflake_FineSection/1000/100</th>\n",
       "      <th>Snowflake_FineTable/1000/100</th>\n",
       "      <th>Snowflake_FineSemantic/1000/100</th>\n",
       "      <th>1v2 Difference</th>\n",
       "      <th>1v3 Difference</th>\n",
       "      <th>1v4 Difference</th>\n",
       "      <th>2v3 Difference</th>\n",
       "      <th>2v4 Difference</th>\n",
       "      <th>3v4 Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.900966</td>\n",
       "      <td>0.692160</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-0.009290</td>\n",
       "      <td>-0.218097</td>\n",
       "      <td>-0.021368</td>\n",
       "      <td>-0.208806</td>\n",
       "      <td>-0.012077</td>\n",
       "      <td>0.196729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.945477</td>\n",
       "      <td>0.969683</td>\n",
       "      <td>0.945677</td>\n",
       "      <td>0.959232</td>\n",
       "      <td>0.024206</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>-0.024006</td>\n",
       "      <td>-0.010451</td>\n",
       "      <td>0.013555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context_recall</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context_precision</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer_correctness</td>\n",
       "      <td>0.417840</td>\n",
       "      <td>0.370029</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.629459</td>\n",
       "      <td>-0.047811</td>\n",
       "      <td>0.066959</td>\n",
       "      <td>0.211619</td>\n",
       "      <td>0.114771</td>\n",
       "      <td>0.259430</td>\n",
       "      <td>0.144660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric  Snowflake_Fine/1000/100  \\\n",
       "0        faithfulness                 0.910256   \n",
       "1    answer_relevancy                 0.945477   \n",
       "2      context_recall                 0.888889   \n",
       "3   context_precision                 1.000000   \n",
       "4  answer_correctness                 0.417840   \n",
       "\n",
       "   Snowflake_FineSection/1000/100  Snowflake_FineTable/1000/100  \\\n",
       "0                        0.900966                      0.692160   \n",
       "1                        0.969683                      0.945677   \n",
       "2                        0.888889                      0.888889   \n",
       "3                        1.000000                      1.000000   \n",
       "4                        0.370029                      0.484800   \n",
       "\n",
       "   Snowflake_FineSemantic/1000/100  1v2 Difference  1v3 Difference  \\\n",
       "0                         0.888889       -0.009290       -0.218097   \n",
       "1                         0.959232        0.024206        0.000200   \n",
       "2                         0.888889        0.000000        0.000000   \n",
       "3                         1.000000        0.000000        0.000000   \n",
       "4                         0.629459       -0.047811        0.066959   \n",
       "\n",
       "   1v4 Difference  2v3 Difference  2v4 Difference  3v4 Difference  \n",
       "0       -0.021368       -0.208806       -0.012077        0.196729  \n",
       "1        0.013755       -0.024006       -0.010451        0.013555  \n",
       "2        0.000000        0.000000        0.000000        0.000000  \n",
       "3        0.000000        0.000000        0.000000        0.000000  \n",
       "4        0.211619        0.114771        0.259430        0.144660  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_results_4(run_model_1, run_model_2, run_model_3, run_model_4):\n",
    "    # Extract results for each model\n",
    "    results_1 = run_model_1.ragas_results\n",
    "    results_2 = run_model_2.ragas_results\n",
    "    results_3 = run_model_3.ragas_results\n",
    "    results_4 = run_model_4.ragas_results\n",
    "\n",
    "    # Create comparison data\n",
    "    comparison_data = {\n",
    "        'Metric': list(results_1.keys()),\n",
    "        run_model_1.name: [results_1[key] for key in results_1.keys()],\n",
    "        run_model_2.name: [results_2[key] for key in results_2.keys()],\n",
    "        run_model_3.name: [results_3[key] for key in results_3.keys()],\n",
    "        run_model_4.name: [results_4[key] for key in results_4.keys()],\n",
    "        '1v2 Difference': [results_2[key] - results_1[key] for key in results_1.keys()],\n",
    "        '1v3 Difference': [results_3[key] - results_1[key] for key in results_1.keys()],\n",
    "        '1v4 Difference': [results_4[key] - results_1[key] for key in results_1.keys()],\n",
    "        '2v3 Difference': [results_3[key] - results_2[key] for key in results_2.keys()],\n",
    "        '2v4 Difference': [results_4[key] - results_2[key] for key in results_2.keys()],\n",
    "        '3v4 Difference': [results_4[key] - results_3[key] for key in results_3.keys()]\n",
    "    }\n",
    "\n",
    "    # Return the dataframe\n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "df = compare_results_4(snowflake_finetune_state , snowflake_finetune_section_state, snowflake_finetune_table_state, snowflake_finetune_semantic_state)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Snowflake_Fine/1000/100</th>\n",
       "      <th>Snowflake_FineSection/1000/100</th>\n",
       "      <th>Snowflake_FineTable/1000/100</th>\n",
       "      <th>Snowflake_FineSemantic/1000/100</th>\n",
       "      <th>1v2 Difference</th>\n",
       "      <th>1v3 Difference</th>\n",
       "      <th>1v4 Difference</th>\n",
       "      <th>2v3 Difference</th>\n",
       "      <th>2v4 Difference</th>\n",
       "      <th>3v4 Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.900966</td>\n",
       "      <td>0.692160</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>-0.009290</td>\n",
       "      <td>-0.218097</td>\n",
       "      <td>-0.021368</td>\n",
       "      <td>-0.208806</td>\n",
       "      <td>-0.012077</td>\n",
       "      <td>0.196729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.945477</td>\n",
       "      <td>0.969683</td>\n",
       "      <td>0.945677</td>\n",
       "      <td>0.959232</td>\n",
       "      <td>0.024206</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>-0.024006</td>\n",
       "      <td>-0.010451</td>\n",
       "      <td>0.013555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context_recall</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context_precision</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer_correctness</td>\n",
       "      <td>0.417840</td>\n",
       "      <td>0.370029</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>0.629459</td>\n",
       "      <td>-0.047811</td>\n",
       "      <td>0.066959</td>\n",
       "      <td>0.211619</td>\n",
       "      <td>0.114771</td>\n",
       "      <td>0.259430</td>\n",
       "      <td>0.144660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Metric  Snowflake_Fine/1000/100  \\\n",
       "0        faithfulness                 0.910256   \n",
       "1    answer_relevancy                 0.945477   \n",
       "2      context_recall                 0.888889   \n",
       "3   context_precision                 1.000000   \n",
       "4  answer_correctness                 0.417840   \n",
       "\n",
       "   Snowflake_FineSection/1000/100  Snowflake_FineTable/1000/100  \\\n",
       "0                        0.900966                      0.692160   \n",
       "1                        0.969683                      0.945677   \n",
       "2                        0.888889                      0.888889   \n",
       "3                        1.000000                      1.000000   \n",
       "4                        0.370029                      0.484800   \n",
       "\n",
       "   Snowflake_FineSemantic/1000/100  1v2 Difference  1v3 Difference  \\\n",
       "0                         0.888889       -0.009290       -0.218097   \n",
       "1                         0.959232        0.024206        0.000200   \n",
       "2                         0.888889        0.000000        0.000000   \n",
       "3                         1.000000        0.000000        0.000000   \n",
       "4                         0.629459       -0.047811        0.066959   \n",
       "\n",
       "   1v4 Difference  2v3 Difference  2v4 Difference  3v4 Difference  \n",
       "0       -0.021368       -0.208806       -0.012077        0.196729  \n",
       "1        0.013755       -0.024006       -0.010451        0.013555  \n",
       "2        0.000000        0.000000        0.000000        0.000000  \n",
       "3        0.000000        0.000000        0.000000        0.000000  \n",
       "4        0.211619        0.114771        0.259430        0.144660  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = compare_results_4(snowflake_finetune_state , snowflake_finetune_section_state, snowflake_finetune_table_state, snowflake_finetune_semantic_state)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
